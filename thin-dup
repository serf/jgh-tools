#!/usr/bin/perl -w
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
#
#   Program: thin-dup
#   Purpose: To find and confirm removal of duplicate copies of files
#   Author:   John Harrison
#   History: See 'perldoc thin-dup'
#
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

use strict;
use Getopt::Long;
use Digest::MD5 qw(md5_hex);
use Time::localtime;
use POSIX qw(:termios_h);
use File::Find ();
use Pod::Usage;

#
# Do magic to read a single key with no <return>
#
my $fd_stdin = fileno(STDIN);
my $term     = POSIX::Termios->new();
$term->getattr($fd_stdin);
my $oterm     = $term->getlflag();

my $echo     = ECHO | ECHOK | ICANON;
my $noecho   = $oterm & ~$echo;

sub cbreak {
    $term->setlflag($noecho);  # ok, so i don't want echo either
    $term->setcc(VTIME, 1);
    $term->setattr($fd_stdin, TCSANOW);
}

sub cooked {
    $term->setlflag($oterm);
    $term->setcc(VTIME, 0);
    $term->setattr($fd_stdin, TCSANOW);
}

sub readkey {
    my $key = '';
    cbreak();
    sysread(STDIN, $key, 1);
    cooked();
    return $key;
}

END { cooked() }

my (@digests);
my (%sizes, %inodes, %files, %info, %digests, %copies, %duplicates);
(my $my_name = $0) =~ s:^.*/::g;

sub usage () {

die <<EOT;
Usage: $my_name OPTIONS
where:

  -r | --recursive - Recurse into subdirectories
  -y | --yes       - Yes, remove
  -n | --no        - No, don't remove (just show groups of matches)
  -i | --include   - Other paths to include (outside this directory)
  -k | --keep      - Keep specified files (requires list of files)
  -m | --master    - Include & Keep specified files (= -i + -k)
  -d | --thin-dir  - same as -r -m DIR (DIR specifies master)

NB: Options -i, -k & -m require a list of files/paths

See 'perldoc thin-dup'
( or: perl -MPod::Perldoc -e '(Pod::Perldoc->run());' thin-dup )
for more details and other options...

EOT

}

#
# Needed for displaying info
#
my @months = ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec');

my @tick = ('|', '/', '-', '\\');
$| = 1;

#
# Process command line arguments
#
my (@include, @keep, @master, @thin_dir);
my %opts;

GetOptions(
    'recursive'  => \$opts{r},
    'r'  => \$opts{r},
    'include=s' => \@include,
    'i=s' => \@include,
    'keep=s' => \@keep,
    'k=s' => \@keep,
    'master=s' => \@master,
    'm=s' => \@master,
    'thin-dir=s' => \@thin_dir,
    'd=s' => \@thin_dir,
    'yes'  => \$opts{f},
    'y'  => \$opts{f},
    'force'  => \$opts{f},
    'f'  => \$opts{f},
    'man'  => \$opts{m},
    'no'  => \$opts{n},
    'n'  => \$opts{n},
    'tick'  => \$opts{t},
    'help'  => \$opts{u},
    'usage'  => \$opts{u},
    'h'  => \$opts{u},
    'u'  => \$opts{u},
    'verbose'  => \$opts{v},
    'v'  => \$opts{v},
    );

if ( $#thin_dir == 0 ) {
    push @master, @thin_dir;
    $opts{r} = 1;
}

$opts{f} = 1 if $opts{y};
$opts{u} = 1 if $opts{h};
usage if $opts{u};
pod2usage(1) if $opts{m};

if ( $#master > -1 ) {

    push @include, @master;
    push @keep, @master;

}

my %keep;
if ( $#keep > -1 ) {

    $keep{$_} = 1 for grep {(-e $_)} @keep;

    print "Keep: ", join " ", keys %keep, $/;

}

#
# Build list of files with File::Find
#
use vars qw/*name *dir *prune/;
*name   = *File::Find::name;
*dir    = *File::Find::dir;
*prune  = *File::Find::prune;

my %found;
sub wanted {

    ( $opts{r} || ( $File::Find::prune = 1 ) ) && ( $found{$name} = 1 );

}

my %entries = map { $_ => 1 } grep {(-e $_ )} glob ".* *";
if ( $#include > -1 ) {

    $entries{$_} = 1 for grep {(-e $_ )} @include;

}

#
# We don't want to go walking off up through our parent
#
delete $entries{'.'};
delete $entries{'..'};

my %to_sum;
File::Find::find({wanted => \&wanted}, sort keys %entries);
$to_sum{$_} = 1 for keys %found;
%found = ();

if ( $#keep > -1 ) {
    File::Find::find({wanted => \&wanted}, sort keys %keep);
    $keep{$_} = 1 for keys %found;
    %found = ();
}

#
# Collect info about the list of files we've built
#
for my $file (sort keys %to_sum) {

    $file =~ s|^\./||;
    next if (-l $file ); # skip symlinks
    next if (-d $file ); # skip directories

    my ($dev,$inode,$mode,$nlink,$uid,$gid,$rdev,$size,
        $atime,$mtime,$ctime,$blksize,$blocks) = stat($file);
    my $time = localtime($mtime);

    $sizes{$size}++; # counting the files of this size
    $inodes{$size}{$sizes{$size}} = $inode;
    $files{$size}{$sizes{$size}} = $file;

    $info{$file} = sprintf "%13i %3s %-2i %02i:%02i:%02i %4i",
        $size, $months[$time->mon], $time->mday,
        $time->hour, $time->min, $time->sec,
        1900 + $time->year;

}

#
# Generate hashes for files with matching sizes
#
my $count;
for my $size (sort {$b <=> $a} keys %sizes) {

    if ($sizes{$size} > 1) {

        for my $i (1..$sizes{$size}) {

            my ($inode, $file) = ($inodes{$size}{$i}, $files{$size}{$i});

            #
            # Don't bother to sum the same inode more than once
            #
            if (! $digests{$inode}) {

                print STDERR "Summing: $file", $/ if ($opts{v});

                if ($opts{t}) {
                    print "\r", $tick[$count++];
                    $count = 0 if ($count eq 4);
                }

                open(FILE, "$file") || die "Can't read '$file': $!\n";
                my $digest = md5_hex(<FILE>);
                close(FILE);
                $digests{$inode} = $digest;
                push(@digests, $digest) unless($copies{$digest}++);
                $duplicates{$digest}{$copies{$digest}} = $file;

            }

        }

    }

}

#
# Process groups of files with the same hash (so the same content)
#
for my $digest (@digests) {

    if ($copies{$digest} > 1) {

        my @duplicates;

        for my $i (1..$copies{$digest}) {

            my $file = $duplicates{$digest}{$i};
            push (@duplicates, $file);
            print "$info{$file} $file\n" if $file;

        }

        my $files = $#duplicates;

        for my $file (@duplicates) {

            my $key;

            if ($keep{$file}) {

                $key = "n";

            } elsif ($opts{f}) {

                $key = "y";

            } elsif ($opts{n}) {

                $key = "n";
                print $/ if $copies{"$digest.seen"}++ == $files;
                next;

            } else {

                #
                # Get user input
                #
                $| = 1;
                print "$my_name: remove regular file `$file'? (y/n/q) ";
                until (defined ($key = lc(readkey())) && $key =~ /^[ynq\004]/){};
                chomp($key);

            }

            if ($key eq 'y') {

                unlink($file) || die "Can't unlink `$file': $!\n";
                print "removed `$file'\n";
                last if ($files-- < 2);

            } elsif ($key eq "\004") {

                die "EOF\n";

            } elsif ($key eq 'q') {

                #
                # I want to quit now
                #
                die $/;

            } else {

                print $/;

            }

        }

    }

}

=head1 NAME

thin-dup - Interactively remove duplicate files

=head1 SYNOPSIS

B<thin-dup> S<[ B<-v> ]> S<[ B<-n> ]> S<[ B<-f> ]> I<perlexpr> S<[ I<files> ]>

 Usage: thin-dup OPTIONS
 where:
   -r | --recursive - Recurse into subdirectories
   -y | --yes       - Yes, remove
   -n | --no        - No, don't remove (just show groups of matches)
   -i | --include   - Other paths to include (outside this directory)
   -k | --keep      - Keep specified files (requires list of files)

 NB: Options -i & -k require a list of files/paths

=head1 DESCRIPTION

C<thin-dup>
Finds duplicate files and asks (unless yes/force option is specified)
for each one whether it should be removed.

By default it will just process the files in the current directory,
without descending into subdirectories.

The optional I<--include> and I<--keep> options both require arguments
of a list of files. C<--include> specifies a list of file (or directories)
to also check for duplicate copies in addition to the current directory
(and subdirectories if I<--recursive> is specified)

I<NB:> If I<--recursive> is specified, it will act both on the current
directory, and any directories matching the path specified in the
I<--include> option.

=head1 OPTIONS

=over 8

=item B<-r>, B<--recursive>

Descend into the subdirectories under this directory
(and any I<--include>d directories) and sum those files too.

=item B<-y>, B<--yes>, B<-f>, B<--force>

Answer all questions 'Yes', i.e. remove all but one file in a group of
matching files.

NB: By default (i.e. unless a specific copy is protected using the
I<--keep> option) only the lexically last file of a list of duplicate
files will be kept. Therefore, you will quite probably want to use the
I<-k> or I<--keep> option to specify which particular cop(y|ies) of
the file you want to keep.

( I<-f> or I<--force> is the same as I<--yes> )

=item B<-n>, B<--no>

Answer all questions 'No', i.e. don't remove ANY files.

This may not seem particularly useful, but it's great if you have a
number of identical copies of several different files and want to know
which groups of files are the same as each other.

i.e. You've copied in a config file from 50 different machines, and
need to see which machines have which version.

=item B<-i> B<--include> B<PATHS>

Other paths to include (outside this directory)

(This option requires an argument of a list of files or paths)

=item B<-k> B<--keep> B<PATHS>

Files to keep

(This option requires an argument of a list of files or paths)

=item B<-m> B<--master> B<PATHS>

Master copy (outside this directory) to compare against but not touch 

(This option requires an argument of a list of files or paths)

This is the same as specifying both -i and -k for a directory.

=item B<-v>, B<--verbose>

Show verbose progress by printing the name of each file as it is summed.

=item B<-t>, B<--tick>

Show a ticker (i.e. | / - \ rotating ) if you've got a large list of
small files to process, so you can see it's still working.

=item B<-h>, B<--help>, B<-u>, B<--usage>

Show a brief usage summary with the most useful options and
recommend reading perldoc for more detailed information.

=back

=head1 EXAMPLES

To check all files in this directory against files in the
directory ../test use:

	thin-dup --include ../test

To check all files in directories under this one, use:

	thin-dup --recursive

To non-interactively remove all duplicate files in sub directories,
but not the copies in this directory, use:

        thin-dup --recursive --yes --keep *

=head1 REVISION HISTORY

 20 Jun 2003 4.0 The fourth major re-write.
     The previous versions were all shell scripts.
     Now it goes like lightning compared to them!
     It uses md5sum to compare any files it finds which are
     the same size and which have different inode numbers.
 19 Jul 2003 4.1
 22 Nov 2004 4.2 Add die messages, verbose flag & tick.
 06 Jun 2011 4.3 Protect filenames in open & die messages
 15 Aug 2011 4.4 Add -n, quit, usage, Getopt:Long -> Getopt::Std
 05 Sep 2011 4.5 Add -r (so use File::Find instead of readdir). Add -k & -o
 06 Sep 2011 5.0 Back to Getopt::Long for command line robustness
     Add documentation.
 23 Nov 2011 5.1 I'm fed up with specifying both -k & -i for the same dir!

=head1 ENVIRONMENT

